{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419a0c98",
   "metadata": {},
   "source": [
    "# Part 4: XML creation\n",
    "## Dependencies: OTIO and pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a85b95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68910a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyloudnorm as pyln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ecbceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video\n",
    "import moviepy\n",
    "from moviepy.editor import *\n",
    "import opentimelineio as otio\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3a7e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9bf31",
   "metadata": {},
   "source": [
    "### Quick summary, OTIO can output XML that CAN be used to import timelines. We just need to learn the behavior and then create a loop to automate clipping, using a imported dataframe as a outline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bb2dd9",
   "metadata": {},
   "source": [
    "# Timeline Outline behavior testing\n",
    "- First create a list of videos\n",
    "    - sfs\n",
    "- Sec create list of audio\n",
    "\n",
    "- Link audio to video, IE if mic1 use center camera\n",
    "\n",
    "## Use the lists of camera and audio to createa loops creating timeranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "852b3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILEPATH_LIST= [\"Middle View.mp4\",\"Scott View.mp4\",\"Zack View.mp4\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "672b069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_VIDEO_TUPLE_LIST=[(\"Mistborn E0 - Scott.wav\", 1), (\"Mistborn E0 - Zack.wav\",2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70f48b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build the structure\n",
    "tl = otio.schema.Timeline(name=\"Example timeline\")\n",
    "\n",
    "# add track for each video file and each audio file\n",
    "#for each file add a track\n",
    "for i in VIDEO_FILEPATH_LIST :\n",
    "    tr = otio.schema.Track(name=i)\n",
    "    tl.tracks.append(tr)\n",
    "\n",
    "for i in AUDIO_VIDEO_TUPLE_LIST:\n",
    "    tr = otio.schema.Track(name=i[0])\n",
    "    tl.tracks.append(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03efb571",
   "metadata": {},
   "source": [
    "# Further data editing \n",
    "\n",
    "## Create a camera view column that matches the audio_video_tuple to  idxmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f07ad689",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_pickle('idxmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76ba6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use indexes of when crossover is 1 to change cam_view to 0 for three seconds after crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62f6cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2. VideoCapture(\"Middle View.mp4\")\n",
    "vlength = int(cap. get(cv2. CAP_PROP_FRAME_COUNT))\n",
    "alength=len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bc36f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26509"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alength\n",
    "vlength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df113f99",
   "metadata": {},
   "source": [
    "## Create intervals of data in tuple form. \n",
    "## Audio Tuples represent the start and end frame of when mic is dominant. Camera 0 is default cam in case of uncertainty, which is center cam in this scenario.\n",
    "## Video Tuples represent the start and end frame of which mic to use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbf64797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_getintervals(series,desiredvalue):\n",
    "    #make sure series is the df['column']\n",
    "    t=series.index[series==desiredvalue].to_series()\n",
    "    interval_list=t.groupby(t.diff().ne(1).cumsum()).agg(['first','last']).apply(tuple,1).tolist()\n",
    "    \n",
    "    return interval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcb2df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of tuples for each camera based on the audio\n",
    "\n",
    "list_of_idxmax_mic_data=[]\n",
    "for i in range(len(AUDIO_VIDEO_TUPLE_LIST)+1):\n",
    "    tuple_list=dataframe_getintervals(data_df['idxmax'],i)\n",
    "    list_of_idxmax_mic_data.append(tuple_list)\n",
    "\n",
    "    \n",
    "##create lists of tuples for each Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d80e0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list to referencing the column names of df \n",
    "list_str_audio_thresholds=[]\n",
    "for irow in range(len(AUDIO_VIDEO_TUPLE_LIST)):\n",
    "    varname=\"A\"\n",
    "    list_str_audio_thresholds.append(varname+str(irow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49637034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of tuples for each audio based the threshold region\n",
    "list_of_tuples_threshold_mic_data=[]\n",
    "for i in range(len(AUDIO_VIDEO_TUPLE_LIST)):\n",
    "    tuple_list=dataframe_getintervals(data_df[list_str_audio_thresholds[i]],1)\n",
    "    list_of_tuples_threshold_mic_data.append(tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55566332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skeletal outline of otio\n",
    "\n",
    "\n",
    "# build the structure\n",
    "tl = otio.schema.Timeline(name=\"Example timeline\")\n",
    "\n",
    "# add track for each video file and each audio file\n",
    "#for each file add a track\n",
    "\n",
    "#create lists for each track to reference back to later\n",
    "#vtr is video track, etc.\n",
    "vtr_list=[]\n",
    "atr_list=[]\n",
    "\n",
    "\n",
    "#add a audio AND video track for each video track\n",
    "    #default cam first because it is lowest priority\n",
    "vtr_default = otio.schema.Track(name=\"Default_camera\", kind=\"Video\")\n",
    "tl.tracks.append(vtr_default)\n",
    "\n",
    "for i in AUDIO_VIDEO_TUPLE_LIST:\n",
    "    atr = otio.schema.Track(name=i[0], kind=\"Audio\")\n",
    "    tl.tracks.append(atr)\n",
    "    atr_list.append(atr)\n",
    "    \n",
    "    #video\n",
    "    vtr = otio.schema.Track(name=i[0]+\"_video\", kind=\"Video\")\n",
    "    tl.tracks.append(vtr)\n",
    "    vtr_list.append(vtr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c171267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vrate=24\n",
    "arate=500\n",
    "arate_actual=24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ec573",
   "metadata": {},
   "source": [
    "# Two different loops, One for Video, another for audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1e12861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video clips\n",
    "# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        #print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            v_clip_starttime=tuples[0]/arate*vrate\n",
    "            v_clip_duration=tuples[1]/arate*vrate-v_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            v_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, vrate),\n",
    "            duration=otio.opentime.RationalTime(vlength, vrate))\n",
    "            \n",
    "            vref = otio.schema.ExternalReference(target_url=vfname,\n",
    "            available_range=v_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            v_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_clip_starttime, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_clip_duration, vrate))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            v_gap_start_time=0\n",
    "            v_gap_duration=v_clip_starttime-vprevious_end_timecode\n",
    "            \n",
    "            v_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_gap_start_time, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_gap_duration, vrate))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            vgap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.start_time.value,\n",
    "                        v_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.duration.value,\n",
    "                        v_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            vtrack.append(vgap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            vcl = otio.schema.Clip(\n",
    "                        name=\"vClip{}\".format(i2 + 1),\n",
    "                        media_reference=vref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.start_time.value,\n",
    "                                v_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.duration.value,\n",
    "                                v_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            vtrack.append(vcl)\n",
    "\n",
    "            vprevious_end_timecode=tuples[1]/arate*vrate\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302d484",
   "metadata": {},
   "source": [
    "# Main speaker audio method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c89026bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mistborn E0 - Scott.wav', 1) Scott View.mp4\n",
      "('Mistborn E0 - Zack.wav', 2) Zack View.mp4\n"
     ]
    }
   ],
   "source": [
    "# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            a_clip_starttime=tuples[0]/arate*arate_actual\n",
    "            a_clip_duration=tuples[1]/arate*arate_actual-a_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            a_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, arate_actual),\n",
    "            duration=otio.opentime.RationalTime(alength*arate_actual, arate_actual))\n",
    "            \n",
    "            aref = otio.schema.ExternalReference(target_url=afname,\n",
    "            available_range=a_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            a_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_clip_starttime, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_clip_duration, arate_actual))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            a_gap_start_time=0\n",
    "            a_gap_duration=a_clip_starttime-aprevious_end_timecode\n",
    "            \n",
    "            a_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_gap_start_time, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_gap_duration, arate_actual))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            agap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.start_time.value,\n",
    "                        a_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.duration.value,\n",
    "                        a_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            atrack.append(agap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            acl = otio.schema.Clip(\n",
    "                        name=\"aClip{}\".format(i2 + 1),\n",
    "                        media_reference=aref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.start_time.value,\n",
    "                                a_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.duration.value,\n",
    "                                a_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            atrack.append(acl)\n",
    "\n",
    "            aprevious_end_timecode=tuples[1]/arate*arate_actual\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24feb8",
   "metadata": {},
   "source": [
    "# Loudness Threshold Audio method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            a_clip_starttime=tuples[0]/arate*arate_actual\n",
    "            a_clip_duration=tuples[1]/arate*arate_actual-a_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            a_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, arate_actual),\n",
    "            duration=otio.opentime.RationalTime(alength*arate_actual, arate_actual))\n",
    "            \n",
    "            aref = otio.schema.ExternalReference(target_url=afname,\n",
    "            available_range=a_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            a_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_clip_starttime, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_clip_duration, arate_actual))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            a_gap_start_time=0\n",
    "            a_gap_duration=a_clip_starttime-aprevious_end_timecode\n",
    "            \n",
    "            a_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_gap_start_time, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_gap_duration, arate_actual))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            agap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.start_time.value,\n",
    "                        a_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.duration.value,\n",
    "                        a_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            atrack.append(agap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            acl = otio.schema.Clip(\n",
    "                        name=\"aClip{}\".format(i2 + 1),\n",
    "                        media_reference=aref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.start_time.value,\n",
    "                                a_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.duration.value,\n",
    "                                a_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            atrack.append(acl)\n",
    "\n",
    "            aprevious_end_timecode=tuples[1]/arate*arate_actual\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42f30bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'videoaudio_beta2.kdenlive'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otio.adapters.write_to_file(tl, 'videoaudio_beta2.kdenlive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3aed1c",
   "metadata": {},
   "source": [
    "# The clip adding via tuple looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11b9ade5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoKnownAdapterForExtensionError",
     "evalue": "No adapter for suffix '' on file 'sc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoKnownAdapterForExtensionError\u001b[0m           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/DL_new/lib/python3.10/site-packages/opentimelineio/adapters/__init__.py:101\u001b[0m, in \u001b[0;36mfrom_filepath\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mActiveManifest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mNoKnownAdapterForExtensionError:\n",
      "File \u001b[0;32m~/anaconda3/envs/DL_new/lib/python3.10/site-packages/opentimelineio/plugins/manifest.py:179\u001b[0m, in \u001b[0;36mManifest.from_filepath\u001b[0;34m(self, suffix)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m adapter\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mNoKnownAdapterForExtensionError(suffix)\n",
      "\u001b[0;31mNoKnownAdapterForExtensionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoKnownAdapterForExtensionError\u001b[0m           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xml_to_otio_test\u001b[38;5;241m=\u001b[39m\u001b[43motio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m otio\u001b[38;5;241m.\u001b[39madapters\u001b[38;5;241m.\u001b[39mwrite_to_file(xml_to_otio_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtests.otio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/DL_new/lib/python3.10/site-packages/opentimelineio/adapters/__init__.py:141\u001b[0m, in \u001b[0;36mread_from_file\u001b[0;34m(filepath, adapter_name, media_linker_name, media_linker_argument_map, **adapter_argument_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_from_file\u001b[39m(\n\u001b[1;32m    126\u001b[0m     filepath,\n\u001b[1;32m    127\u001b[0m     adapter_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madapter_argument_map\n\u001b[1;32m    131\u001b[0m ):\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124;03m\"\"\"Read filepath using adapter_name.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    If adapter_name is None, try and infer the adapter name from the filepath.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m        timeline = read_from_file(\"file_with_no_extension\", \"cmx_3600\")\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     adapter \u001b[38;5;241m=\u001b[39m \u001b[43m_from_filepath_or_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m adapter\u001b[38;5;241m.\u001b[39mread_from_file(\n\u001b[1;32m    144\u001b[0m         filepath\u001b[38;5;241m=\u001b[39mfilepath,\n\u001b[1;32m    145\u001b[0m         media_linker_name\u001b[38;5;241m=\u001b[39mmedia_linker_name,\n\u001b[1;32m    146\u001b[0m         media_linker_argument_map\u001b[38;5;241m=\u001b[39mmedia_linker_argument_map,\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madapter_argument_map\n\u001b[1;32m    148\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/DL_new/lib/python3.10/site-packages/opentimelineio/adapters/__init__.py:88\u001b[0m, in \u001b[0;36m_from_filepath_or_name\u001b[0;34m(filepath, adapter_name)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m plugins\u001b[38;5;241m.\u001b[39mActiveManifest()\u001b[38;5;241m.\u001b[39mfrom_name(adapter_name)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DL_new/lib/python3.10/site-packages/opentimelineio/adapters/__init__.py:103\u001b[0m, in \u001b[0;36mfrom_filepath\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m plugins\u001b[38;5;241m.\u001b[39mActiveManifest()\u001b[38;5;241m.\u001b[39mfrom_filepath(outext)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mNoKnownAdapterForExtensionError:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mNoKnownAdapterForExtensionError(\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo adapter for suffix \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    105\u001b[0m             outext,\n\u001b[1;32m    106\u001b[0m             filepath\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m     )\n",
      "\u001b[0;31mNoKnownAdapterForExtensionError\u001b[0m: No adapter for suffix '' on file 'sc'"
     ]
    }
   ],
   "source": [
    "xml_to_otio_test=otio.adapters.read_from_file('sc')\n",
    "otio.adapters.write_to_file(xml_to_otio_test, \"tests.otio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opentimelineio.plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "otio.schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b599c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
